{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID BLOCK\n",
    "- @author Eric Zair\n",
    "- @zairea200@potsdam.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Regression (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first notebook we explored multiple regression using Turi Create. Now we will use Turi Create along with numpy to solve for the regression weights with gradient descent.\n",
    "\n",
    "In this notebook we will cover estimating multiple regression weights via gradient descent. You will:\n",
    "* Add a constant column of 1's to a Turi Create SFrame to account for the intercept\n",
    "* Convert an SFrame into a Numpy array\n",
    "* Write a predict_output() function using Numpy\n",
    "* Write a numpy function to compute the derivative of the regression weights with respect to a single feature\n",
    "* Write gradient descent function to compute the regression weights given an initial weight vector, step size and tolerance.\n",
    "* Use the gradient descent function to estimate regression weights for multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up Turi Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the latest version of Turi Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turicreate import SFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "load data from home_dats.sframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = SFrame(\"../Multiple_input/home_data.sframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although SFrames offer a number of benefits to users (especially when using Big Data and built-in Turi Create functions) in order to understand the details of the implementation of algorithms it's important to work with a library that allows for direct (and optimized) matrix operations. Numpy is a Python solution to work with matrices (or any multi-dimensional \"array\").\n",
    "\n",
    "Recall that the predicted value given the weights and the features is just the dot product between the feature and weight vector. Similarly, if we put all of the features row-by-row in a matrix then the predicted value for *all* the observations can be computed by right multiplying the \"feature matrix\" by the \"weight vector\". \n",
    "\n",
    "First we need to take the SFrame of our data and convert it into a 2D numpy array (also called a matrix). To do this we use Turi Create's built in .to_dataframe() which converts the SFrame into a Pandas (another python library) dataframe. We can then use Panda's .as_matrix() to convert the dataframe into a numpy matrix.\n",
    "\n",
    "import numpy here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that will accept an SFrame, a list of feature names (e.g. ['sqft_living', 'bedrooms']) and an target feature e.g. ('price') and will return two things:\n",
    "* A numpy matrix whose columns are the desired features plus a constant column (this is how we create an 'intercept')\n",
    "* A numpy array containing the values of the output\n",
    "\n",
    "With this in mind, complete the following function (where there's an empty line you should write a line of code that does what the comment above indicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sales.column_names()\n",
    "features.remove('price')\n",
    "\n",
    "\n",
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe.to_numpy()\n",
    "\n",
    "    # This simply adds the constant column that we will need.\n",
    "    data_sframe['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    features_sframe = data_sframe[features]\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "\n",
    "    output_sarray = data_sframe[output]\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    print(output_array.shape)\n",
    "    return feature_matrix, output_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing let's use the 'sqft_living' feature and a constant as our features and price as our output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(21613,)\n[1.00e+00 1.18e+03]\n221900.0\n"
    }
   ],
   "source": [
    "# the [] around 'sqft_living' makes it a list\n",
    "example_features, example_output = get_numpy_data(sales, ['sqft_living'], 'price') \n",
    "# this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print(example_features[0,:])\n",
    "\n",
    "print(example_output[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting output given regression weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we had the weights [1.0, 1.0] and the features [1.0, 1180.0] and we wanted to compute the predicted output 1.0\\*1.0 + 1.0\\*1180.0 = 1181.0 this is the dot product between these two arrays. If they're numpy arrays we can use np.dot() to compute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(2,)\n0.0\n"
    }
   ],
   "source": [
    "my_weights = np.array([0., 0.])\n",
    "#  use the first data point of example_features and calculate the dot product \n",
    "#  and that should be 1181.0\n",
    "# yi_hat is our predicted. value.\n",
    "print(my_weights.shape)\n",
    "my_features  = example_features[0,]\n",
    "predicted_value = np.dot(my_features, my_weights)\n",
    "print(predicted_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.dot() also works when dealing with a matrix and a vector. Recall that the predictions from all the observations is just the RIGHT (as in weights on the right) dot product between the features *matrix* and the weights *vector*. With this in mind finish the following predict_output function to compute the predictions for an entire matrix of features given the matrix and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as \n",
    "    # columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions =  np.dot(feature_matrix, weights)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test your code run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.0\n0.0\n"
    }
   ],
   "source": [
    "test_predictions = predict_output(example_features, my_weights)\n",
    "\n",
    "# should be 1181 example_feature\n",
    "print(test_predictions[0])\n",
    "\n",
    "# should be 2571.0\n",
    "print(test_predictions[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to move to computing the derivative of the regression cost function. Recall that the cost function is the sum over the data points of the squared difference between an observed output and a predicted output.\n",
    "\n",
    "Since the derivative of a sum is the sum of the derivatives, we can compute the derivative for a single data point and then sum over data points. We can write the squared difference between the observed output and predicted output for a single point as follows:\n",
    "\n",
    "(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)^2\n",
    "\n",
    "Where we have k features and a constant. So the derivative with respect to weight w[i] by the chain rule is:\n",
    "\n",
    "2\\*(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)\\* [feature_i]\n",
    "\n",
    "The term inside the paranethesis is just the error (difference between prediction and output). So we can re-write this as:\n",
    "\n",
    "2\\*error\\*[feature_i]\n",
    "\n",
    "That is, the derivative for the weight for feature i is the sum (over data points) of 2 times the product of the error and the feature itself. In the case of the constant then this is just twice the sum of the errors!\n",
    "\n",
    "Recall that twice the sum of the product of two vectors is just twice the dot product of the two vectors. Therefore the derivative for the weight for feature_i is just two times the dot product between the values of feature_i and the current errors. \n",
    "\n",
    "With this in mind complete the following derivative function which computes the derivative of the weight given the value of the feature (over all data points) and the errors (over all data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same \n",
    "    # length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' \n",
    "    # and return the value.\n",
    "    # g decent is just partial derivaive of each features (all of them).\n",
    "    print(errors)\n",
    "    derivative =  -2 * np.dot(errors, feature)\n",
    "\n",
    "    print(\"errors\", errors.shape)\n",
    "\n",
    "    print(\"features:\", feature.shape)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your feature derivartive for single feature Sqft_living and price as output.\n",
    "Your weights for testing are 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(21613,)\n[-221900. -538000. -180000. ... -402101. -400000. -325000.]\nerrors (21613,)\nfeatures: (21613,)\n23345850022.0\n-23345850022.0\n"
    }
   ],
   "source": [
    "example_features, example_output = get_numpy_data(sales, ['sqft_living'], 'price') \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "test_predictions = predict_output(example_features, my_weights) \n",
    "\n",
    "# just like SFrames 2 numpy arrays can be elementwise subtracted with '-': \n",
    "errors = test_predictions - example_output\n",
    "\n",
    "# the -example_output\n",
    "feature = example_features[:,0] # let's compute the derivative with respect to \n",
    "#'constant', the \":\" indicates \"all rows\"\n",
    "derivative = feature_derivative(errors, feature)\n",
    "print(derivative)\n",
    "print(-np.sum(example_output)*2) # should be the same as derivative and it is -23345850022.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that performs a gradient descent. The basic premise is simple. Given a starting point we update the current weights by moving in the negative gradient direction. Recall that the gradient is the direction of *increase* and therefore the negative gradient is the direction of *decrease* and we're trying to *minimize* a cost function. \n",
    "\n",
    "The amount by which we move in the negative gradient *direction*  is called the 'step size'. We stop when we are 'sufficiently close' to the optimum. We define this by requiring that the magnitude (length) of the gradient vector to be smaller than a fixed 'tolerance'.\n",
    "\n",
    "With this in mind, complete the following gradient descent function below using your derivative function above. For each step in the gradient descent we update the weight for each feature befofe computing our stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False\n",
    "    weights = np.array(initial_weights)\n",
    "\n",
    "    while not converged:\n",
    "        # Calucate our prediction.\n",
    "        predictions = predict_output(feature_matrix, weights)\n",
    "        errors = predictions - output\n",
    "        gradient_sum_of_squares = 0\n",
    "\n",
    "        # Do partial derivative for each thing.\n",
    "        for i in range(len(weights)):\n",
    "            derivative = feature_derivative(errors, feature_matrix[:,i])\n",
    "            derivative_squared = derivative ** 2\n",
    "            gradient_sum_of_squares += derivative_squared\n",
    "            weights[i] += (step_size * derivative)\n",
    "        \n",
    "        # Now we need to update magnitude, to know if we need to converge.\n",
    "        gradient_magnitude = sqrt(gradient_sum_of_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note before we run the gradient descent. Since the gradient is a sum over all the data points and involves a product of an error and a feature, the gradient itself will be very large since the features are large (squarefeet) and the output is large (prices). So while you might expect \"tolerance\" to be small, small is only relative to the size of the features. \n",
    "\n",
    "For similar reasons the step size will be much smaller than you might expect but this is because the gradient has such large values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Gradient Descent as Simple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's split the data into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = sales.random_split(.8,seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the gradient descent is designed for multiple regression since the constant is now a feature we can use the gradient descent function to estimate the parameters in the simple regression on squarefeet. The following cell sets up the feature_matrix, output, initial weights and step size for the first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(17384,)\n[-4.7e+04  1.0e+00]\n"
    }
   ],
   "source": [
    "# let's test out the gradient descent\n",
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "simple_feature_matrix, output = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7\n",
    "print(initial_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run your gradient descent with the above parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[-267720. -582430. -226230. ... -405470. -445400. -370980.]\nerrors (17384,)\nfeatures: (17384,)\n[-267720. -582430. -226230. ... -405470. -445400. -370980.]\nerrors (17384,)\nfeatures: (17384,)\n[149835.75268253 326992.10740189  46242.87107465 ... 135936.99307949\n 120777.24115888 -10041.95721323]\nerrors (17384,)\nfeatures: (17384,)\n[149835.75268253 326992.10740189  46242.87107465 ... 135936.99307949\n 120777.24115888 -10041.95721323]\nerrors (17384,)\nfeatures: (17384,)\n[  41402.97905279   90829.24562979  -24514.12116057 ...   -4658.0329602\n  -26250.23536279 -103771.98688413]\nerrors (17384,)\nfeatures: (17384,)\n[  41402.97905279   90829.24562979  -24514.12116057 ...   -4658.0329602\n  -26250.23536279 -103771.98688413]\nerrors (17384,)\nfeatures: (17384,)\n[ 69561.29400806 152157.08979222  -6139.62417287 ...  31852.3217235\n  11930.52726658 -79431.74723328]\nerrors (17384,)\nfeatures: (17384,)\n[ 69561.29400806 152157.08979222  -6139.62417287 ...  31852.3217235\n  11930.52726658 -79431.74723328]\nerrors (17384,)\nfeatures: (17384,)\n[ 62249.01493414 136231.19678206 -10911.19697784 ...  22371.14705412\n   2015.57347812 -85752.53117785]\nerrors (17384,)\nfeatures: (17384,)\n[ 62249.01493414 136231.19678206 -10911.19697784 ...  22371.14705412\n   2015.57347812 -85752.53117785]\nerrors (17384,)\nfeatures: (17384,)\n[ 64147.9007599  140366.90498524  -9672.09329217 ...  24833.26153607\n   4590.3336913  -84111.1213092 ]\nerrors (17384,)\nfeatures: (17384,)\n[ 64147.9007599  140366.90498524  -9672.09329217 ...  24833.26153607\n   4590.3336913  -84111.1213092 ]\nerrors (17384,)\nfeatures: (17384,)\n[ 63654.78946435 139292.92550245  -9993.86936703 ...  24193.88846675\n   3921.70826723 -84537.3700796 ]\nerrors (17384,)\nfeatures: (17384,)\n[ 63654.78946435 139292.92550245  -9993.86936703 ...  24193.88846675\n   3921.70826723 -84537.3700796 ]\nerrors (17384,)\nfeatures: (17384,)\n[ 63782.84284131 139571.82137077  -9910.30909904 ...  24359.92376599\n   4095.33995093 -84426.67986712]\nerrors (17384,)\nfeatures: (17384,)\n[ 63782.84284131 139571.82137077  -9910.30909904 ...  24359.92376599\n   4095.33995093 -84426.67986712]\nerrors (17384,)\nfeatures: (17384,)\n[ 63749.58935592 139499.39642565  -9932.00841284 ...  24316.80696341\n   4050.25048491 -84455.4244075 ]\nerrors (17384,)\nfeatures: (17384,)\n[ 63749.58935592 139499.39642565  -9932.00841284 ...  24316.80696341\n   4050.25048491 -84455.4244075 ]\nerrors (17384,)\nfeatures: (17384,)\n[ 63758.22476891 139518.20406441  -9926.37344055 ...  24328.00372821\n   4061.95952007 -84447.9598982 ]\nerrors (17384,)\nfeatures: (17384,)\n[ 63758.22476891 139518.20406441  -9926.37344055 ...  24328.00372821\n   4061.95952007 -84447.9598982 ]\nerrors (17384,)\nfeatures: (17384,)\n[ 63755.98228259 139513.32001158  -9927.83675978 ...  24325.09609924\n   4058.91886257 -84449.89831931]\nerrors (17384,)\nfeatures: (17384,)\n[ 63755.98228259 139513.32001158  -9927.83675978 ...  24325.09609924\n   4058.91886257 -84449.89831931]\nerrors (17384,)\nfeatures: (17384,)\n[ 63756.56461854 139514.58832478  -9927.45676243 ...  24325.85116328\n   4059.70847223 -84449.39494476]\nerrors (17384,)\nfeatures: (17384,)\n[ 63756.56461854 139514.58832478  -9927.45676243 ...  24325.85116328\n   4059.70847223 -84449.39494476]\nerrors (17384,)\nfeatures: (17384,)\n[-46999.88716555    281.91211912]\n"
    }
   ],
   "source": [
    "test_weights = regression_gradient_descent(simple_feature_matrix,\n",
    "                                           output, initial_weights,\n",
    "                                           step_size, tolerance)\n",
    "print(test_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do your weights compare to those achieved in week 1 (don't expect them to be exactly the same)? \n",
    "\n",
    "**Quiz Question: What is the value of the weight for sqft_living -- the second element of ‘simple_weights’ (rounded to 1 decimal place)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre>Linear regression:</pre>",
      "text/plain": "Linear regression:"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>--------------------------------------------------------</pre>",
      "text/plain": "--------------------------------------------------------"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>Number of examples          : 17384</pre>",
      "text/plain": "Number of examples          : 17384"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>Number of features          : 1</pre>",
      "text/plain": "Number of features          : 1"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>Number of unpacked features : 1</pre>",
      "text/plain": "Number of unpacked features : 1"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>Number of coefficients    : 2</pre>",
      "text/plain": "Number of coefficients    : 2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>Starting Newton Method</pre>",
      "text/plain": "Starting Newton Method"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>--------------------------------------------------------</pre>",
      "text/plain": "--------------------------------------------------------"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>+-----------+----------+--------------+--------------------+---------------------------------+</pre>",
      "text/plain": "+-----------+----------+--------------+--------------------+---------------------------------+"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>| Iteration | Passes   | Elapsed Time | Training Max Error | Training Root-Mean-Square Error |</pre>",
      "text/plain": "| Iteration | Passes   | Elapsed Time | Training Max Error | Training Root-Mean-Square Error |"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>+-----------+----------+--------------+--------------------+---------------------------------+</pre>",
      "text/plain": "+-----------+----------+--------------+--------------------+---------------------------------+"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>| 1         | 2        | 0.003757     | 4349521.926170     | 262943.613754                   |</pre>",
      "text/plain": "| 1         | 2        | 0.003757     | 4349521.926170     | 262943.613754                   |"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>+-----------+----------+--------------+--------------------+---------------------------------+</pre>",
      "text/plain": "+-----------+----------+--------------+--------------------+---------------------------------+"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre>SUCCESS: Optimal solution found.</pre>",
      "text/plain": "SUCCESS: Optimal solution found."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre></pre>",
      "text/plain": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+-------------+-------+-------------------+-------------------+\n|     name    | index |       value       |       stderr      |\n+-------------+-------+-------------------+-------------------+\n| (intercept) |  None | -47114.0206702149 | 4923.344377526256 |\n| sqft_living |  None | 281.9578501659871 | 2.164054653233476 |\n+-------------+-------+-------------------+-------------------+\n[2 rows x 4 columns]\n\n"
    }
   ],
   "source": [
    "import turicreate\n",
    "model_for_sqft = turicreate.linear_regression.create(train_data, target=my_output, features=simple_features, validation_set=None)\n",
    "print(model_for_sqft.coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your newly estimated weights and your predict_output() function to compute the predictions on all the TEST data (you will need to create a numpy array of the test feature_matrix and test output first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(4229,)\n[[1.00e+00 1.43e+03]\n [1.00e+00 2.95e+03]\n [1.00e+00 1.71e+03]\n ...\n [1.00e+00 2.52e+03]\n [1.00e+00 2.31e+03]\n [1.00e+00 1.02e+03]]\n[310000. 650000. 233000. ... 610685. 400000. 402101.]\n"
    }
   ],
   "source": [
    "test_features, test_output = get_numpy_data(test_data, simple_features, my_output)\n",
    "print(test_features)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute your predictions using test_simple_feature_matrix and your weights from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[356134.44317093 784640.86422788 435069.83652353 ... 663418.65300782\n 604217.10799338 240550.4743332 ]\n"
    }
   ],
   "source": [
    "predictions = predict_output(test_features, test_weights)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 1 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "356134.0\n"
    }
   ],
   "source": [
    "print(predictions[0].round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the predictions on test data, compute the RSS on the test data set. Save this value for comparison later. Recall that RSS is the sum of the squared errors (difference between prediction and output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "275400047593155.94\n"
    }
   ],
   "source": [
    "rss_errors = predictions - test_output\n",
    "# Then square and add them up\n",
    "\n",
    "RSS = (rss_errors**2).sum()\n",
    "print(RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a multiple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use more than one actual feature. Use the following code to produce the weights for a second model with the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(17384,)\n[[1.00e+00 1.18e+03 1.34e+03]\n [1.00e+00 2.57e+03 1.69e+03]\n [1.00e+00 7.70e+02 2.72e+03]\n ...\n [1.00e+00 1.53e+03 1.53e+03]\n [1.00e+00 1.60e+03 1.41e+03]\n [1.00e+00 1.02e+03 1.02e+03]]\n"
    }
   ],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15'] \n",
    "# sqft_living15 is the average squarefeet for the nearest 15 neighbors. \n",
    "my_output = 'price'\n",
    "(feature_matrix, output) = get_numpy_data(train_data, model_features, my_output)\n",
    "initial_weights_2 = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9\n",
    "print (feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above parameters to estimate the model weights for train data. Record these values for your quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2 -108420.42181793]\nerrors (17384,)\nfeatures: (17384,)\n[  54822.00408109  101994.10309769   86756.29890389 ...   14868.27972028\n  -15855.134504   -108421.13637627]\nerrors (17384,)\nfeatures: (17384,)\n[  54822.00408109  101994.10309769   86756.29890389 ...   14868.27972028\n  -15855.134504   -108421.13637627]\nerrors (17384,)\nfeatures: (17384,)\n[  54822.00408109  101994.10309769   86756.29890389 ...   14868.27972028\n  -15855.134504   -108421.13637627]\nerrors (17384,)\nfeatures: (17384,)\n[  54819.81347433  101999.95508273   86738.90995621 ...   14867.23331717\n  -15854.58578587 -108421.83398083]\nerrors (17384,)\nfeatures: (17384,)\n[  54819.81347433  101999.95508273   86738.90995621 ...   14867.23331717\n  -15854.58578587 -108421.83398083]\nerrors (17384,)\nfeatures: (17384,)\n[  54819.81347433  101999.95508273   86738.90995621 ...   14867.23331717\n  -15854.58578587 -108421.83398083]\nerrors (17384,)\nfeatures: (17384,)\n[  54817.67484252  102005.66822181   86721.93358387 ...   14866.2117413\n  -15854.05008682 -108422.51503387]\nerrors (17384,)\nfeatures: (17384,)\n[  54817.67484252  102005.66822181   86721.93358387 ...   14866.2117413\n  -15854.05008682 -108422.51503387]\nerrors (17384,)\nfeatures: (17384,)\n[  54817.67484252  102005.66822181   86721.93358387 ...   14866.2117413\n  -15854.05008682 -108422.51503387]\nerrors (17384,)\nfeatures: (17384,)\n[  54815.58695248  102011.24580924   86705.359998   ...   14865.21440361\n  -15853.52709796 -108423.17992809]\nerrors (17384,)\nfeatures: (17384,)\n[  54815.58695248  102011.24580924   86705.359998   ...   14865.21440361\n  -15853.52709796 -108423.17992809]\nerrors (17384,)\nfeatures: (17384,)\n[  54815.58695248  102011.24580924   86705.359998   ...   14865.21440361\n  -15853.52709796 -108423.17992809]\nerrors (17384,)\nfeatures: (17384,)\n[  54813.5486003   102016.69106115   86689.17964195 ...   14864.24072902\n  -15853.01651772 -108423.82904689]\nerrors (17384,)\nfeatures: (17384,)\n[  54813.5486003   102016.69106115   86689.17964195 ...   14864.24072902\n  -15853.01651772 -108423.82904689]\nerrors (17384,)\nfeatures: (17384,)\n[  54813.5486003   102016.69106115   86689.17964195 ...   14864.24072902\n  -15853.01651772 -108423.82904689]\nerrors (17384,)\nfeatures: (17384,)\n[  54811.55861063  102022.00711739   86673.38318583 ...   14863.2901561\n  -15852.5180517  -108424.46276455]\nerrors (17384,)\nfeatures: (17384,)\n[  54811.55861063  102022.00711739   86673.38318583 ...   14863.2901561\n  -15852.5180517  -108424.46276455]\nerrors (17384,)\nfeatures: (17384,)\n[  54811.55861063  102022.00711739   86673.38318583 ...   14863.2901561\n  -15852.5180517  -108424.46276455]\nerrors (17384,)\nfeatures: (17384,)\n[  54809.61583602  102027.19704328   86657.96152114 ...   14862.36213672\n  -15852.03141246 -108425.08144649]\nerrors (17384,)\nfeatures: (17384,)\n[  54809.61583602  102027.19704328   86657.96152114 ...   14862.36213672\n  -15852.03141246 -108425.08144649]\nerrors (17384,)\nfeatures: (17384,)\n[  54809.61583602  102027.19704328   86657.96152114 ...   14862.36213672\n  -15852.03141246 -108425.08144649]\nerrors (17384,)\nfeatures: (17384,)\n[  54807.71915621  102032.26383142   86642.90575545 ...   14861.45613578\n  -15851.5563194  -108425.68544944]\nerrors (17384,)\nfeatures: (17384,)\n[  54807.71915621  102032.26383142   86642.90575545 ...   14861.45613578\n  -15851.5563194  -108425.68544944]\nerrors (17384,)\nfeatures: (17384,)\n[  54807.71915621  102032.26383142   86642.90575545 ...   14861.45613578\n  -15851.5563194  -108425.68544944]\nerrors (17384,)\nfeatures: (17384,)\n[  54805.86747755  102037.21040344   86628.20720733 ...   14860.57163085\n  -15851.09249857 -108426.2751217 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54805.86747755  102037.21040344   86628.20720733 ...   14860.57163085\n  -15851.09249857 -108426.2751217 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54805.86747755  102037.21040344   86628.20720733 ...   14860.57163085\n  -15851.09249857 -108426.2751217 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54804.05973233  102042.03961159   86613.85740134 ...   14859.70811192\n  -15850.63968252 -108426.85080326]\nerrors (17384,)\nfeatures: (17384,)\n[  54804.05973233  102042.03961159   86613.85740134 ...   14859.70811192\n  -15850.63968252 -108426.85080326]\nerrors (17384,)\nfeatures: (17384,)\n[  54804.05973233  102042.03961159   86613.85740134 ...   14859.70811192\n  -15850.63968252 -108426.85080326]\nerrors (17384,)\nfeatures: (17384,)\n[  54802.29487817  102046.7542405    86599.84806312 ...   14858.86508107\n  -15850.19761016 -108427.41282608]\nerrors (17384,)\nfeatures: (17384,)\n[  54802.29487817  102046.7542405    86599.84806312 ...   14858.86508107\n  -15850.19761016 -108427.41282608]\nerrors (17384,)\nfeatures: (17384,)\n[  54802.29487817  102046.7542405    86599.84806312 ...   14858.86508107\n  -15850.19761016 -108427.41282608]\nerrors (17384,)\nfeatures: (17384,)\n[  54800.57189742  102051.35700871   86586.17111463 ...   14858.04205219\n  -15849.76602657 -108427.96151424]\nerrors (17384,)\nfeatures: (17384,)\n[  54800.57189742  102051.35700871   86586.17111463 ...   14858.04205219\n  -15849.76602657 -108427.96151424]\nerrors (17384,)\nfeatures: (17384,)\n[  54800.57189742  102051.35700871   86586.17111463 ...   14858.04205219\n  -15849.76602657 -108427.96151424]\nerrors (17384,)\nfeatures: (17384,)\n[  54798.8897966   102055.85057026   86572.81866948 ...   14857.23855071\n  -15849.34468289 -108428.4971841 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54798.8897966   102055.85057026   86572.81866948 ...   14857.23855071\n  -15849.34468289 -108428.4971841 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54798.8897966   102055.85057026   86572.81866948 ...   14857.23855071\n  -15849.34468289 -108428.4971841 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54797.24760575  102060.23751621   86559.78302842 ...   14856.45411331\n  -15848.93333618 -108429.02014456]\nerrors (17384,)\nfeatures: (17384,)\n[  54797.24760575  102060.23751621   86559.78302842 ...   14856.45411331\n  -15848.93333618 -108429.02014456]\nerrors (17384,)\nfeatures: (17384,)\n[  54797.24760575  102060.23751621   86559.78302842 ...   14856.45411331\n  -15848.93333618 -108429.02014456]\nerrors (17384,)\nfeatures: (17384,)\n[  54795.64437798  102064.52037616   86547.05667487 ...   14855.68828768\n  -15848.53174923 -108429.53069714]\nerrors (17384,)\nfeatures: (17384,)\n[  54795.64437798  102064.52037616   86547.05667487 ...   14855.68828768\n  -15848.53174923 -108429.53069714]\nerrors (17384,)\nfeatures: (17384,)\n[  54795.64437798  102064.52037616   86547.05667487 ...   14855.68828768\n  -15848.53174923 -108429.53069714]\nerrors (17384,)\nfeatures: (17384,)\n[  54794.07918883  102068.70161968   86534.63227056 ...   14854.94063222\n  -15848.13969048 -108430.02913626]\nerrors (17384,)\nfeatures: (17384,)\n[  54794.07918883  102068.70161968   86534.63227056 ...   14854.94063222\n  -15848.13969048 -108430.02913626]\nerrors (17384,)\nfeatures: (17384,)\n[  54794.07918883  102068.70161968   86534.63227056 ...   14854.94063222\n  -15848.13969048 -108430.02913626]\nerrors (17384,)\nfeatures: (17384,)\n[  54792.55113578  102072.78365776   86522.50265137 ...   14854.21071583\n  -15847.75693387 -108430.51574931]\nerrors (17384,)\nfeatures: (17384,)\n[  54792.55113578  102072.78365776   86522.50265137 ...   14854.21071583\n  -15847.75693387 -108430.51574931]\nerrors (17384,)\nfeatures: (17384,)\n[  54792.55113578  102072.78365776   86522.50265137 ...   14854.21071583\n  -15847.75693387 -108430.51574931]\nerrors (17384,)\nfeatures: (17384,)\n[  54791.05933774  102076.76884418   86510.66082314 ...   14853.49811763\n  -15847.38325869 -108430.99081689]\nerrors (17384,)\nfeatures: (17384,)\n[  54791.05933774  102076.76884418   86510.66082314 ...   14853.49811763\n  -15847.38325869 -108430.99081689]\nerrors (17384,)\nfeatures: (17384,)\n[  54791.05933774  102076.76884418   86510.66082314 ...   14853.49811763\n  -15847.38325869 -108430.99081689]\nerrors (17384,)\nfeatures: (17384,)\n[  54789.6029345   102080.65947686   86499.09995765 ...   14852.80242671\n  -15847.01844947 -108431.45461292]\nerrors (17384,)\nfeatures: (17384,)\n[  54789.6029345   102080.65947686   86499.09995765 ...   14852.80242671\n  -15847.01844947 -108431.45461292]\nerrors (17384,)\nfeatures: (17384,)\n[  54789.6029345   102080.65947686   86499.09995765 ...   14852.80242671\n  -15847.01844947 -108431.45461292]\nerrors (17384,)\nfeatures: (17384,)\n[  54788.18108627  102084.45779922   86487.8133887  ...   14852.12324193\n  -15846.66229586 -108431.90740484]\nerrors (17384,)\nfeatures: (17384,)\n[  54788.18108627  102084.45779922   86487.8133887  ...   14852.12324193\n  -15846.66229586 -108431.90740484]\nerrors (17384,)\nfeatures: (17384,)\n[  54788.18108627  102084.45779922   86487.8133887  ...   14852.12324193\n  -15846.66229586 -108431.90740484]\nerrors (17384,)\nfeatures: (17384,)\n[  54786.79297321  102088.16600143   86476.79460825 ...   14851.46017166\n  -15846.31459249 -108432.34945374]\nerrors (17384,)\nfeatures: (17384,)\n[  54786.79297321  102088.16600143   86476.79460825 ...   14851.46017166\n  -15846.31459249 -108432.34945374]\nerrors (17384,)\nfeatures: (17384,)\n[  54786.79297321  102088.16600143   86476.79460825 ...   14851.46017166\n  -15846.31459249 -108432.34945374]\nerrors (17384,)\nfeatures: (17384,)\n[  54785.43779489  102091.78622172   86466.03726266 ...   14850.81283357\n  -15845.97513886 -108432.7810145 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54785.43779489  102091.78622172   86466.03726266 ...   14850.81283357\n  -15845.97513886 -108432.7810145 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54785.43779489  102091.78622172   86466.03726266 ...   14850.81283357\n  -15845.97513886 -108432.7810145 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54784.11476989  102095.32054757   86455.53514906 ...   14850.18085438\n  -15845.64373925 -108433.20233598]\nerrors (17384,)\nfeatures: (17384,)\n[  54784.11476989  102095.32054757   86455.53514906 ...   14850.18085438\n  -15845.64373925 -108433.20233598]\nerrors (17384,)\nfeatures: (17384,)\n[  54784.11476989  102095.32054757   86455.53514906 ...   14850.18085438\n  -15845.64373925 -108433.20233598]\nerrors (17384,)\nfeatures: (17384,)\n[  54782.82313534  102098.77101693   86445.28221174 ...   14849.56386969\n  -15845.32020255 -108433.6136611 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54782.82313534  102098.77101693   86445.28221174 ...   14849.56386969\n  -15845.32020255 -108433.6136611 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54782.82313534  102098.77101693   86445.28221174 ...   14849.56386969\n  -15845.32020255 -108433.6136611 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54781.56214646  102102.13961942   86435.27253866 ...   14848.96152373\n  -15845.00434221 -108434.01522706]\nerrors (17384,)\nfeatures: (17384,)\n[  54781.56214646  102102.13961942   86435.27253866 ...   14848.96152373\n  -15845.00434221 -108434.01522706]\nerrors (17384,)\nfeatures: (17384,)\n[  54781.56214646  102102.13961942   86435.27253866 ...   14848.96152373\n  -15845.00434221 -108434.01522706]\nerrors (17384,)\nfeatures: (17384,)\n[  54780.33107613  102105.42829742   86425.50035807 ...   14848.37346918\n  -15844.69597611 -108434.40726539]\nerrors (17384,)\nfeatures: (17384,)\n[  54780.33107613  102105.42829742   86425.50035807 ...   14848.37346918\n  -15844.69597611 -108434.40726539]\nerrors (17384,)\nfeatures: (17384,)\n[  54780.33107613  102105.42829742   86425.50035807 ...   14848.37346918\n  -15844.69597611 -108434.40726539]\nerrors (17384,)\nfeatures: (17384,)\n[  54779.12921451  102108.63894725   86415.96003515 ...   14847.79936696\n  -15844.39492642 -108434.79000215]\nerrors (17384,)\nfeatures: (17384,)\n[  54779.12921451  102108.63894725   86415.96003515 ...   14847.79936696\n  -15844.39492642 -108434.79000215]\nerrors (17384,)\nfeatures: (17384,)\n[  54779.12921451  102108.63894725   86415.96003515 ...   14847.79936696\n  -15844.39492642 -108434.79000215]\nerrors (17384,)\nfeatures: (17384,)\n[  54777.95586858  102111.77342024   86406.64606877 ...   14847.23888603\n  -15844.10101956 -108435.16365804]\nerrors (17384,)\nfeatures: (17384,)\n[  54777.95586858  102111.77342024   86406.64606877 ...   14847.23888603\n  -15844.10101956 -108435.16365804]\nerrors (17384,)\nfeatures: (17384,)\n[  54777.95586858  102111.77342024   86406.64606877 ...   14847.23888603\n  -15844.10101956 -108435.16365804]\nerrors (17384,)\nfeatures: (17384,)\n[  54776.81036176  102114.83352377   86397.55308834 ...   14846.6917032\n  -15843.81408606 -108435.5284485 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54776.81036176  102114.83352377   86397.55308834 ...   14846.6917032\n  -15843.81408606 -108435.5284485 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54776.81036176  102114.83352377   86397.55308834 ...   14846.6917032\n  -15843.81408606 -108435.5284485 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54775.69203354  102117.82102235   86388.67585068 ...   14846.15750297\n  -15843.53396046 -108435.88458389]\nerrors (17384,)\nfeatures: (17384,)\n[  54775.69203354  102117.82102235   86388.67585068 ...   14846.15750297\n  -15843.53396046 -108435.88458389]\nerrors (17384,)\nfeatures: (17384,)\n[  54775.69203354  102117.82102235   86388.67585068 ...   14846.15750297\n  -15843.53396046 -108435.88458389]\nerrors (17384,)\nfeatures: (17384,)\n[  54774.60023907  102120.73763864   86380.009237   ...   14845.63597731\n  -15843.26048123 -108436.23226956]\nerrors (17384,)\nfeatures: (17384,)\n[  54774.60023907  102120.73763864   86380.009237   ...   14845.63597731\n  -15843.26048123 -108436.23226956]\nerrors (17384,)\nfeatures: (17384,)\n[  54774.60023907  102120.73763864   86380.009237   ...   14845.63597731\n  -15843.26048123 -108436.23226956]\nerrors (17384,)\nfeatures: (17384,)\n[  54773.5343488   102123.5850544    86371.54824998 ...   14845.12682548\n  -15842.99349069 -108436.57170598]\nerrors (17384,)\nfeatures: (17384,)\n[  54773.5343488   102123.5850544    86371.54824998 ...   14845.12682548\n  -15842.99349069 -108436.57170598]\nerrors (17384,)\nfeatures: (17384,)\n[  54773.5343488   102123.5850544    86371.54824998 ...   14845.12682548\n  -15842.99349069 -108436.57170598]\nerrors (17384,)\nfeatures: (17384,)\n[  54772.49374812  102126.36491151   86363.28801087 ...   14844.62975392\n  -15842.73283488 -108436.90308889]\nerrors (17384,)\nfeatures: (17384,)\n[  54772.49374812  102126.36491151   86363.28801087 ...   14844.62975392\n  -15842.73283488 -108436.90308889]\nerrors (17384,)\nfeatures: (17384,)\n[  54772.49374812  102126.36491151   86363.28801087 ...   14844.62975392\n  -15842.73283488 -108436.90308889]\nerrors (17384,)\nfeatures: (17384,)\n[  54771.47783701  102129.07881289   86355.22375666 ...   14844.14447599\n  -15842.47836349 -108437.22660935]\nerrors (17384,)\nfeatures: (17384,)\n[  54771.47783701  102129.07881289   86355.22375666 ...   14844.14447599\n  -15842.47836349 -108437.22660935]\nerrors (17384,)\nfeatures: (17384,)\n[  54771.47783701  102129.07881289   86355.22375666 ...   14844.14447599\n  -15842.47836349 -108437.22660935]\nerrors (17384,)\nfeatures: (17384,)\n[  54770.48602967  102131.72832342   86347.35083734 ...   14843.67071189\n  -15842.22992981 -108437.54245393]\nerrors (17384,)\nfeatures: (17384,)\n[  54770.48602967  102131.72832342   86347.35083734 ...   14843.67071189\n  -15842.22992981 -108437.54245393]\nerrors (17384,)\nfeatures: (17384,)\n[  54770.48602967  102131.72832342   86347.35083734 ...   14843.67071189\n  -15842.22992981 -108437.54245393]\nerrors (17384,)\nfeatures: (17384,)\n[  54769.5177542   102134.31497086   86339.66471327 ...   14843.20818842\n  -15841.98739057 -108437.85080473]\nerrors (17384,)\nfeatures: (17384,)\n[  54769.5177542   102134.31497086   86339.66471327 ...   14843.20818842\n  -15841.98739057 -108437.85080473]\nerrors (17384,)\nfeatures: (17384,)\n[  54769.5177542   102134.31497086   86339.66471327 ...   14843.20818842\n  -15841.98739057 -108437.85080473]\nerrors (17384,)\nfeatures: (17384,)\n[  54768.57245229  102136.84024671   86332.16095246 ...   14842.75663889\n  -15841.75060592 -108438.15183956]\nerrors (17384,)\nfeatures: (17384,)\n[  54768.57245229  102136.84024671   86332.16095246 ...   14842.75663889\n  -15841.75060592 -108438.15183956]\nerrors (17384,)\nfeatures: (17384,)\n[  54768.57245229  102136.84024671   86332.16095246 ...   14842.75663889\n  -15841.75060592 -108438.15183956]\nerrors (17384,)\nfeatures: (17384,)\n[  54767.64957886  102139.3056071    86324.83522813 ...   14842.31580293\n  -15841.51943933 -108438.44573199]\nerrors (17384,)\nfeatures: (17384,)\n[  54767.64957886  102139.3056071    86324.83522813 ...   14842.31580293\n  -15841.51943933 -108438.44573199]\nerrors (17384,)\nfeatures: (17384,)\n[  54767.64957886  102139.3056071    86324.83522813 ...   14842.31580293\n  -15841.51943933 -108438.44573199]\nerrors (17384,)\nfeatures: (17384,)\n[  54766.74860175  102141.71247359   86317.68331612 ...   14841.88542635\n  -15841.2937575  -108438.7326515 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54766.74860175  102141.71247359   86317.68331612 ...   14841.88542635\n  -15841.2937575  -108438.7326515 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54766.74860175  102141.71247359   86317.68331612 ...   14841.88542635\n  -15841.2937575  -108438.7326515 ]\nerrors (17384,)\nfeatures: (17384,)\n[  54765.86900146  102144.06223404   86310.70109251 ...   14841.46526098\n  -15841.07343029 -108439.01276352]\nerrors (17384,)\nfeatures: (17384,)\n[  54765.86900146  102144.06223404   86310.70109251 ...   14841.46526098\n  -15841.07343029 -108439.01276352]\nerrors (17384,)\nfeatures: (17384,)\n[  54765.86900146  102144.06223404   86310.70109251 ...   14841.46526098\n  -15841.07343029 -108439.01276352]\nerrors (17384,)\nfeatures: (17384,)\n[  54765.01027079  102146.35624335   86303.88453122 ...   14841.05506455\n  -15840.85833067 -108439.28622957]\nerrors (17384,)\nfeatures: (17384,)\n[  54765.01027079  102146.35624335   86303.88453122 ...   14841.05506455\n  -15840.85833067 -108439.28622957]\nerrors (17384,)\nfeatures: (17384,)\n[  54765.01027079  102146.35624335   86303.88453122 ...   14841.05506455\n  -15840.85833067 -108439.28622957]\nerrors (17384,)\nfeatures: (17384,)\n[  54764.17191458  102148.5958243    86297.22970171 ...   14840.65460053\n  -15840.6483346  -108439.55320733]\nerrors (17384,)\nfeatures: (17384,)\n[  54764.17191458  102148.5958243    86297.22970171 ...   14840.65460053\n  -15840.6483346  -108439.55320733]\nerrors (17384,)\nfeatures: (17384,)\n[  54764.17191458  102148.5958243    86297.22970171 ...   14840.65460053\n  -15840.6483346  -108439.55320733]\nerrors (17384,)\nfeatures: (17384,)\n[  54763.35344942  102150.78226827   86290.73276667 ...   14840.26363801\n  -15840.44332099 -108439.81385075]\nerrors (17384,)\nfeatures: (17384,)\n[  54763.35344942  102150.78226827   86290.73276667 ...   14840.26363801\n  -15840.44332099 -108439.81385075]\nerrors (17384,)\nfeatures: (17384,)\n[  54763.35344942  102150.78226827   86290.73276667 ...   14840.26363801\n  -15840.44332099 -108439.81385075]\nerrors (17384,)\nfeatures: (17384,)\n[  54762.55440338  102152.916836     86284.38997985 ...   14839.88195156\n  -15840.24317163 -108440.06831012]\nerrors (17384,)\nfeatures: (17384,)\n[  54762.55440338  102152.916836     86284.38997985 ...   14839.88195156\n  -15840.24317163 -108440.06831012]\nerrors (17384,)\nfeatures: (17384,)\n[  54762.55440338  102152.916836     86284.38997985 ...   14839.88195156\n  -15840.24317163 -108440.06831012]\nerrors (17384,)\nfeatures: (17384,)\n[  54761.77431569  102155.00075832   86278.19768389 ...   14839.50932108\n  -15840.0477711  -108440.31673216]\nerrors (17384,)\nfeatures: (17384,)\n[  54761.77431569  102155.00075832   86278.19768389 ...   14839.50932108\n  -15840.0477711  -108440.31673216]\nerrors (17384,)\nfeatures: (17384,)\n[  54761.77431569  102155.00075832   86278.19768389 ...   14839.50932108\n  -15840.0477711  -108440.31673216]\nerrors (17384,)\nfeatures: (17384,)\n[  54761.01273657  102157.03523686   86272.15230819 ...   14839.14553171\n  -15839.85700674 -108440.55926011]\nerrors (17384,)\nfeatures: (17384,)\n[  54761.01273657  102157.03523686   86272.15230819 ...   14839.14553171\n  -15839.85700674 -108440.55926011]\nerrors (17384,)\nfeatures: (17384,)\n[  54761.01273657  102157.03523686   86272.15230819 ...   14839.14553171\n  -15839.85700674 -108440.55926011]\nerrors (17384,)\nfeatures: (17384,)\nintercept: -99999.96884886503\nsqft: 245.07260254240242\nsqft 15: 65.27952766842058\n"
    }
   ],
   "source": [
    "reg_weights = regression_gradient_descent(feature_matrix, output, initial_weights_2, step_size, tolerance)\n",
    "print('intercept: {}'.format(reg_weights[0]))\n",
    "print('sqft: {}'.format(reg_weights[1]))\n",
    "print('sqft 15: {}'.format(reg_weights[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your newly estimated weights and the predict_output function to compute the predictions on the TEST data. Don't forget to create a numpy array for these features from the test set first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(4229,)\n[366651.41203656 762662.39786164 386312.09499712 ... 682087.39928241\n 585579.27865729 216559.20396617]\n"
    }
   ],
   "source": [
    "multiple_features, multiple_output = get_numpy_data(test_data, model_features, my_output)\n",
    "multiple_predictions = predict_output(multiple_features, reg_weights)\n",
    "print(multiple_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 2 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "366651.0\n"
    }
   ],
   "source": [
    "print(multiple_predictions[0].round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the actual price for the 1st house in the test data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "310000.0\n"
    }
   ],
   "source": [
    "print(test_data[0]['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: Which estimate was closer to the true price for the 1st house on the TEST data set, model 1 or model 2?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It appears that the first model was closer, but still is by thousands. Each model comepletly overestimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your predictions and the output to compute the RSS for model 2 on TEST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "270263446465244.06\n"
    }
   ],
   "source": [
    "err = multiple_predictions - multiple_output\n",
    "RSS_model_2 = (err**2).sum()\n",
    "print(RSS_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: Which model (1 or 2) has lowest RSS on all of the TEST data? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "First Model: 275400047593155.94\nSecond Model: 270263446465244.06\n"
    }
   ],
   "source": [
    "print(\"First Model: {}\".format(RSS))\n",
    "print(\"Second Model: {}\".format(RSS_model_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model to is lower."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}